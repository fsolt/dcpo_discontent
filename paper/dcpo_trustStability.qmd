---
format:
  pdf:
    number-sections: true
    papersize: a4
    keep-tex: false
    # thanks: "Yue Hu appreciates the funding support from the National Natural Science Foundation of China (72374116)."
crossref:
  sec-prefix: OSM
  sec-labels: alpha A
# author:
#   - name: Yuehong 'Cassandra' Tai
#     email: yhcasstai@psu.edu
#     orcid: 0000-0001-7303-7443
#     affiliations:
#       - ref: psu
#   - name: Yue Hu
#     corresponding: true
#     affiliations:
#       - ref: tsu
#     orcid: 0000-0002-2829-3971
#     email: yuehu@tsinghua.edu.cn
#     url: https://sammo3182.github.io
#   - name: Haofeng Ma
#     orcid: https://orcid.org/0000-0003-4379-8449
#     email: haofeng-ma@uiowa.edu
#     affiliations:
#       - ref: ui
#   - name: Frederick Solt
#     orcid: 0000-0002-3154-6132
#     email: frederick-solt@uiowa.edu
#     affiliations:
#       - ref: ui
# affiliations:
#   - id: tsu
#     name: Department of Political Science, Tsinghua University, Beijing, China
#   - id: psu
#     name: Center for Social Data Analytics, Penn State University, PA, U.S.
#   - id: ui
#     name: Department of Political Science, University of Iowa, IA, U.S.
citeproc: false # to make multibib and wordcount work
filters:
  - multibib # separate bib for main and appendix
  - at: pre-render
    path: "_extensions/andrewheiss/wordcount/wordcount.lua"
validate-yaml: false # for multibib to work
  # - authors-block
# reference of multibib: https://www.andrewheiss.com/blog/2023/12/11/separate-bibliographies-quarto/
bibliography: 
    main: p_dcpo_trustRegime_main.bib
    appendix: p_dcpo_trustRegime_app.bib
citation_package: natbib
tables: true # enable longtable and booktabs
fontsize: 12pt
indent: true
geometry: margin=1in
linestretch: 1.5 # double spacing using linestretch 1.5
colorlinks: true
link-citations: true
execute:
  echo: false
  message: false
  warning: false
  dpi: 300
editor_options: 
  chunk_output_type: console
title:  "Political Discontent and Regime Instability"
# subtitle: |
abstract: |
    Put abstract here.
    And here.
keywords: 
    - Political discontent
    - Regime stability
    - Cross-national panel
---

\pagenumbering{gobble}

# Authors {.unlisted .unnumbered}

-   Haofeng Ma, ORCID: <https://orcid.org/0000-0003-4379-8449>, Ph.D. Candidate, Department of Political Science, University of Iowa, [haofeng-ma\@uiowa.edu](mailto:haofeng-ma@uiowa.edu){.email}
-   Jeongho Choi, ORCID: <https://orcid.org/0000-0002-8060-7907>, Ph.D. Candidate, Department of Political Science, University of Iowa, [jeongho-choi\@uiowa.edu](mailto:jeongho-choi@uiowa.edu){.email}
-   Yuehong Cassandra Tai, ORCID: <https://orcid.org/0000-0001-7303-7443>, Postdoctoral Fellow, Center for Social Data Analytics, Pennsylvania State University, [yhcasstai\@psu.edu](mailto:yhcasstai@psu.edu){.email}
-   Yue Hu, ORCID: <https://orcid.org/0000-0002-2829-3971>, Associate Professor, Department of Political Science, Tsinghua University, [yuehu\@tsinghua.edu.cn](mailto:yuehu@tsinghua.edu.cn){.email}
-   Frederick Solt, ORCID: <https://orcid.org/0000-0002-3154-6132>, Professor, Department of Political Science, University of Iowa, [frederick-solt\@uiowa.edu](mailto:frederick-solt@uiowa.edu){.email}

# Data Availability Statement {.unlisted .unnumbered}
Replication data is available on the Harvard Dataverse [link tbd], and the work's complete revision history is available at https://github.com/fsolt/trust_stability.

\pagebreak

```{=tex}
\renewcommand{\baselinestretch}{1}
\selectfont
\maketitle
\renewcommand{\baselinestretch}{1.5}
\selectfont
\pagenumbering{arabic}
```
```{=tex}
\begin{abstract}
abstract
\end{abstract}
```

```{r setup, include=FALSE}
if (!require(pacman)) install.packages("pacman")
library(pacman)
p_install(janitor, force = FALSE)
#p_install_gh(c("fsolt/DCPOtools"), force = FALSE)
if (!require(posterior))
    install.packages("posterior")

p_load(
    DCPOtools,
    cmdstanr,
    tidyverse,
    here,
    countrycode,
    patchwork,
    ggthemes,
    rsdmx,
    osfr,
    kableExtra,
    rnaturalearth, # maps
    rnaturalearthdata, # maps
    sf, # maps
    tabulapdf # scrape pdfs
)

theme_set(theme_minimal())
set.seed(313)

conflicted::conflicts_prefer(dplyr::filter,
                             dplyr::select,
                             posterior::sd,
                             posterior::mad,
                             DCPOtools::extract_dcpo_results)
```

```{r define_funs}
# define functions
validation_plot <- function(v_data_raw,
                            lab_x = .38, lab_y = 92,
                            theta_summary, theta_results,
                            survey = TRUE) {
    
    # defaults per https://stackoverflow.com/a/49167744/2620381
    if ("theta_summary" %in% ls(envir = .GlobalEnv) & missing(theta_summary))
        theta_summary <- get("theta_summary", envir = .GlobalEnv)
    if ("theta_results" %in% ls(envir = .GlobalEnv) & missing(theta_results))
        theta_results <- get("theta_results", envir = .GlobalEnv)
    
    median_val <- Vectorize(function(x) median(1:x),
                            vectorize.args = "x")
    if (survey) {    
        v_vars <- v_data_raw %>% 
            select(item0 = item) %>% 
            unique() %>% 
            mutate(v_val = str_extract(item0, "\\d+") %>% 
                       as.numeric() %>% 
                       median_val(.) %>%
                       `+`(.6) %>% 
                       round())
        
        validation_summarized <- v_data_raw %>% 
            DCPOtools::format_dcpo(scale_q = v_vars$item0[[1]], # these arguments are required
                                   scale_cp = 1) %>% # but they don't matter
            pluck("data") %>% 
            mutate(item0 = str_remove(item, " \\d or higher"),
                   title = factor(v_data_raw %>%
                                      pull(title) %>%
                                      first()), 
                   levels = v_data_raw %>%
                       pull(title) %>%
                       unique(),
                   neg = v_data_raw %>% 
                       pull(neg) %>% 
                       first) %>% 
            right_join(v_vars, by = "item0") %>%
            arrange(title) %>% 
            filter(str_detect(item, paste(v_val, "or higher"))) %>%
            mutate(iso2c = countrycode::countrycode(country,
                                                    origin = "country.name",
                                                    destination = "iso2c",
                                                    warn = FALSE),
                   prop = if_else(neg, 1-y_r/n_r, y_r/n_r),
                   se = sqrt((prop*(1-prop))/n),
                   prop_90 = prop + qnorm(.9)*se,
                   prop_10 = prop - qnorm(.9)*se) %>%
            inner_join(theta_summary %>% select(-kk, -tt), by = c("country", "year"))
    } else {
        validation_summarized <- v_data_raw %>% 
            mutate(iso2c = countrycode::countrycode(country,
                                                    origin = "country.name",
                                                    destination = "iso2c",
                                                    warn = FALSE),
                   prop = prop,
                   se = se,
                   prop_90 = prop + qnorm(.9)*se,
                   prop_10 = prop - qnorm(.9)*se) %>%
            inner_join(theta_summary %>% select(-kk, -tt), by = c("country", "year"))
    }
    
    validation_cor <- theta_results %>%
        inner_join(validation_summarized %>%
                       select(country, year, title, prop, se),
                   by = c("country", "year")) %>% 
        rowwise() %>% 
        mutate(sim = rnorm(1, mean = prop, sd = se)) %>% 
        ungroup() %>% 
        select(title, theta, sim, draw) %>% 
        nest(data = c(theta, sim)) %>% 
        mutate(r = lapply(data, function(df) cor(df)[2,1]) %>% 
                   unlist()) %>%
        select(-data) %>% 
        group_by(title) %>% 
        summarize(r = paste("R =", sprintf("%.2f", round(mean(r), 2))))
    
    if ({validation_summarized %>%
            pull(country) %>%
            unique() %>% 
            length()} > 1) {
        val_plot <- validation_summarized %>%
            ggplot(aes(x = mean,
                       y = prop * 100)) +
            geom_segment(aes(x = q10, xend = q90,
                             y = prop * 100, yend = prop * 100),
                         na.rm = TRUE,
                         alpha = .2) +
            geom_segment(aes(x = mean, xend = mean,
                             y = prop_90 * 100, yend = prop_10 * 100),
                         na.rm = TRUE,
                         alpha = .2) +
            geom_smooth(method = 'lm', formula = 'y ~ x', se = FALSE) +
            facet_wrap(~ title, ncol = 4) +
            geom_label(data = validation_cor, aes(x = lab_x,
                                                  y = lab_y,
                                                  label = r),
                       size = 2)
    } else {
        val_plot <- validation_summarized %>%
            ggplot(aes(x = year,
                       y = mean)) +
            geom_line() +
            geom_ribbon(aes(ymin = q10,
                            ymax = q90,
                            linetype = NA),
                        alpha = .2) +
            geom_point(aes(y = prop),
                       fill = "black",
                       shape = 21,
                       size = .5,
                       na.rm = TRUE) +
            geom_path(aes(y = prop),
                      linetype = 3,
                      na.rm = TRUE,
                      alpha = .7) +
            geom_segment(aes(x = year, xend = year,
                             y = prop_90, yend = prop_10),
                         na.rm = TRUE,
                         alpha = .2) +
            facet_wrap(~ title, ncol = 4) +
            geom_label(data = validation_cor, aes(x = lab_x,
                                                  y = lab_y,
                                                  label = r),
                       size = 2)
    }
    
    return(val_plot)
}

covered_share_of_spanned <- function(dcpo_input_raw) {
    n_cy <- dcpo_input_raw %>%
        distinct(country, year) %>% 
        nrow()
    
    spanned_cy <- dcpo_input_raw %>% 
        group_by(country) %>% 
        summarize(years = max(year) - min(year) + 1) %>% 
        summarize(n = sum(years)) %>% 
        pull(n)
    
    {(n_cy/spanned_cy) * 100}
}

get_coef <- function(iv, results_df = coef_data, type = "both", width = .95) {
    result_var <- results_df %>% 
        filter(.width == width) %>% 
        pull(.variable) %>% 
        str_subset(iv)
    
    if (!type=="both") {
        res <- results_df %>% 
            filter(.variable == result_var & .width == width) %>% 
            pull({{type}})
    } else {
        sc <- results_df %>% 
            filter(.variable == result_var & .width == width) %>% 
            pull(std_coef)
        
        ci <- results_df %>% 
            filter(.variable == result_var & .width == width) %>% 
            pull(ci)
        
        res <- paste0(sc, " (95% c.i.: ", ci, ")")
    }
    
    return(res)
}

by2sd <- function(var) {
    dich <- stats::na.omit(unique(var)) %>% 
        sort() %>% 
        identical(c(0, 1))
    if (dich) 
        sd <- 1
    else 
        sd <- 2 * stats::sd(var, na.rm = TRUE)
    
    return(sd)
}

pairwise_count <- function(x) {
    x <- !is.na(x)
    n <- crossprod(x)
    return(n)
}

long_corr <- function(x) {
    n_long <- crossprod(!is.na(x)) %>% 
        as.data.frame() %>% 
        rownames_to_column(var = "item1") %>% 
        pivot_longer(cols = -item1,
                     names_to = "item2",
                     values_to = "n")
    
    cor(x, use = "pairwise.complete.obs") %>% 
        as.data.frame() %>% 
        rownames_to_column(var = "item1") %>% 
        pivot_longer(cols = -item1,
                     names_to = "item2",
                     values_to = "corr") %>% 
        filter(!is.na(corr)) %>% 
        left_join(n_long, by = join_by(item1, item2))
}

set.seed(324)
```


Intro does not need a header.


```{r dcpo_input_raw, eval=FALSE, include=FALSE}
# set eval to TRUE to run; running time is <5 minutes
surveys_pd <- read_csv(here::here("data-raw",
                                  "surveys_pd.csv"),
                       col_types = "cccc")

item_groups <- c("eff",
                 "trust_eff",
                 "corrupt",
                 "sat",
                 "trust")

items_by_group <- map(item_groups, \(g) {
    surveys_pd %>% 
        filter(group == g) %>% 
        pull(item) %>% 
        unique() %>% 
        sort()
}) %>% 
    set_names(item_groups)

dcpo_input_raw <- DCPOtools::dcpo_setup(vars = surveys_pd,
                                        datapath = here::here("..",
                                                              "data", "dcpo_surveys"),
                                        file = here::here("data",
                                                          "dcpo_input_raw.csv"))

dcpo_input_raw %>% 
    group_by(country, year, item) %>% 
    summarize(avg = sum(r*n)/sum(n)) %>%
    pivot_wider(names_from = item, values_from = avg) %>%
    ungroup() %>%
    select(unname(unlist(items_by_group))) %>%
    long_corr() %>%
    View("long_corr")
```

```{r pd_summary_stats}
surveys_pd <- read_csv(here::here("data-raw",
                                  "surveys_pd.csv"),
                       col_types = "cccc")

dcpo_input_raw <- read_csv(here::here("data", "dcpo_input_raw.csv"),
                           col_types = "cdcddcd")

process_dcpo_input_raw <- function(dcpo_input_raw_df) {
    dcpo_input_raw_df %>% 
        filter(year >= 1968 & !country == "Northern Cyprus") %>% 
        with_min_yrs(3) %>% 
        with_min_cy(5) %>% 
        group_by(country) %>% 
        mutate(cc_rank = n()) %>% 
        ungroup() %>% 
        arrange(-cc_rank)
} 

dcpo_input_raw1 <- process_dcpo_input_raw(dcpo_input_raw)

n_surveys <- surveys_pd %>%
    distinct(survey) %>% 
    nrow()

n_items <- dcpo_input_raw1 %>%
    distinct(item) %>% 
    nrow()

n_countries <- dcpo_input_raw1 %>%
    distinct(country) %>% 
    nrow()

n_cy <- dcpo_input_raw1 %>%
    distinct(country, year) %>% 
    nrow() %>% 
    scales::comma()

n_years <- as.integer(summary(dcpo_input_raw1$year)[6]-summary(dcpo_input_raw1$year)[1] + 1)

spanned_cy <- dcpo_input_raw1 %>% 
    group_by(country) %>% 
    summarize(years = max(year) - min(year) + 1) %>% 
    summarize(n = sum(years)) %>% 
    pull(n) %>% 
    scales::comma()

total_cy <- {n_countries * n_years} %>% 
    scales::comma()

year_range <- paste("from",
                    summary(dcpo_input_raw1$year)[1],
                    "to",
                    summary(dcpo_input_raw1$year)[6])

n_cyi <- dcpo_input_raw1 %>% 
    distinct(country, year, item) %>% 
    nrow() %>% 
    scales::comma()

back_to_numeric <- function(string_number) {
    string_number %>% 
        str_replace(",", "") %>% 
        as.numeric()
}

covered_share_of_spanned <- {back_to_numeric(n_cy)/back_to_numeric(spanned_cy) * 100}
```

```{r itemcountry, fig.cap="Countries and Years with the Most Observations in the Source Data \\label{item_country_plots}", fig.height=3.5, fig.pos='h', cache=FALSE}
items_plot <- dcpo_input_raw1 %>%
    distinct(country, year, item) %>%
    count(item) %>%
    arrange(desc(n)) %>% 
    head(12) %>% 
    ggplot(aes(forcats::fct_reorder(item, n, .desc = TRUE), n)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
          axis.title.y = element_text(size = 9),
          plot.title = element_text(hjust = 0.5, size = 11)) +
    ylab("Country-Years\nObserved") +
    ggtitle("Items")

most_common_item <- dcpo_input_raw1 %>% 
    distinct(country, year, item) %>% 
    count(item) %>% 
    arrange(-n) %>% 
    slice(1) %>% 
    pull(item)

most_common_item_cy <- dcpo_input_raw1 %>%
    filter(item == most_common_item) %>%
    distinct(country, year) %>%
    nrow()

most_common_item_surveys <- dcpo_input_raw1 %>%
    filter(item == most_common_item) %>%
    distinct(survey) %>%
    pull(survey)

countries_plot <- dcpo_input_raw1 %>%
    mutate(country = if_else(stringr::str_detect(country, "United"),
                             stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                             country)) %>% 
    distinct(country, year, item) %>% 
    count(country) %>%
    arrange(desc(n)) %>% 
    head(12) %>% 
    ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          axis.text.x  = element_text(angle = 90,
                                      vjust = .45,
                                      hjust = .95,
                                      size = 6),
          axis.title.y = element_text(size = 9),
          plot.title = element_text(hjust = 0.5, 
                                    size = 11)) +
    ylab("Year-Items\nObserved") +
    ggtitle("Countries")

cby_plot <- dcpo_input_raw1 %>%
    mutate(country = if_else(stringr::str_detect(country, "United"),
                             stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                             country),
           country = stringr::str_replace(country, "South", "S.")) %>% 
    distinct(country, year) %>%
    count(country) %>% 
    arrange(desc(n)) %>% 
    head(12) %>% 
    ggplot(aes(forcats::fct_reorder(country, n, .desc = TRUE), n)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          axis.text.x  = element_text(angle = 90,
                                      vjust = .45,
                                      hjust = .95,
                                      size = 7),
          axis.title.y = element_text(size = 9),
          plot.title = element_text(hjust = 0.5,
                                    size = 11)) +
    ylab("Years\nObserved") +
    ggtitle("Countries")


ybc_plot <- dcpo_input_raw1 %>%
    distinct(country, year) %>%
    count(year, name = "nn") %>%
    ggplot(aes(year, nn)) +
    geom_bar(stat = "identity") +
    theme_bw() +
    theme(axis.title.x = element_blank(),
          # axis.text.x  = element_text(angle = 90, vjust = .45, hjust = .95),
          axis.title.y = element_text(size = 9),
          plot.title = element_text(hjust = 0.5, size = 11)) +
    ylab("Countries\nObserved") +
    ggtitle("Years")

us_obs <- dcpo_input_raw1 %>% 
    distinct(country, year, item) %>%
    count(country) %>%
    filter(country == "United States") %>%
    pull(n)

others <- dcpo_input_raw1 %>%
    distinct(country, year, item) %>%
    count(country) %>%
    arrange(desc(n)) %>%
    slice(2:5) %>%
    pull(country) %>% 
    paste(collapse = ", ") %>% 
    str_replace(", (\\w+)$", ", and \\1") %>% 
    str_replace("United", "the United")

countries_cp <- dcpo_input_raw1 %>%
    mutate(country = if_else(stringr::str_detect(country, "United"),
                             stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                             country),
           country = stringr::str_replace(country, "South", "S.")) %>% 
    distinct(country, year, item) %>%
    count(country) %>% 
    arrange(desc(n)) %>% 
    head(12) %>% 
    pull(country)

countries_cbyp <- dcpo_input_raw1 %>%
    mutate(country = if_else(stringr::str_detect(country, "United"),
                             stringr::str_replace(country, "((.).*) ((.).*)", "\\2.\\4."),
                             country),
           country = stringr::str_replace(country, "South", "S.")) %>% 
    distinct(country, year) %>%
    count(country) %>% 
    arrange(desc(n)) %>% 
    head(12) %>% 
    pull(country)

adding <- setdiff(countries_cbyp, countries_cp) %>% 
    knitr::combine_words()

dropping <- setdiff(countries_cp, countries_cbyp) %>% 
    knitr::combine_words()

y_peak_year <- dcpo_input_raw1 %>%
    distinct(country, year) %>%
    count(year, name = "nn") %>% 
    filter(nn == max(nn)) %>% 
    pull(year)

y_peak_nn <- dcpo_input_raw1 %>%
    distinct(country, year) %>%
    count(year, name = "nn") %>% 
    filter(nn == max(nn)) %>% 
    pull(nn)

data_poorest <- dcpo_input_raw1 %>%
    distinct(country, year, item) %>%
    count(country) %>%
    arrange(n) %>%
    filter(n == 3) %>%
    pull(country) %>% 
    knitr::combine_words()

wordify_numeral <- function(x) setNames(c("one", "two", "three", "four", "five", "six", "seven", "eight", "nine", "ten", "eleven", "twelve", "thirteen", "fourteen", "fifteen", "sixteen", " seventeen", "eighteen", "nineteen"), 1:19)[x]

n_data_poorest <- {data_poorest %>%
        str_split(",") %>% 
        first()} %>% 
    length() %>% 
    wordify_numeral()

world_map <- map_data("world") %>% 
    filter(!long > 180)

cby_map <- world_map %>% 
    distinct(region) %>% 
    mutate(country = countrycode::countrycode(region,
                                              "country.name",
                                              "country.name")) %>% 
    filter(!region=="Antarctica") %>% 
    left_join(dcpo_input_raw1 %>% 
                  count(country, year) %>% 
                  count(country, name = "Years"),
              by = "country") %>% 
    mutate(Years = ifelse(is.na(Years), 0, Years)) %>% 
    ggplot(aes(fill = Years, map_id = region)) +
    geom_map(map = world_map,
             color = "white",
             linewidth = 0.06) +
    coord_map(projection = "mollweide", 
              ylim=c(-80, 90),
              xlim=c(-170, 170)) +
    theme_void() +
    scale_fill_distiller(na.value = "gray90", 
                         palette = "Blues",
                         direction = 1) +
    ggtitle("Years Observed by Country") +
    theme(plot.title = element_text(hjust = 0.5),
          legend.position = c(.05,.1),
          legend.justification = c(0,0), 
          legend.direction = "vertical") +
    scale_y_continuous(expand=c(0,0)) +
    scale_x_continuous(expand=c(0,0))

cby_map + (countries_plot/ ybc_plot) + plot_layout(widths = c(4, 1))
```

# Estimates {.unlisted .unnumbered}

```{r dcpo_input, eval=FALSE, include=FALSE, results=FALSE}
dcpo_input <- DCPOtools::format_dcpo(dcpo_input_raw1,
                                     scale_q = "big2",
                                     scale_cp = 1)
save(dcpo_input, file = here::here("data", "dcpo_input.rda"))
```

```{r dcpo, eval=FALSE, include=FALSE, results=FALSE}
iter <- 1000

dcpo <- paste0(.libPaths(), "/DCPO/stan/dcpo.stan")[1] |> 
    cmdstan_model()

dcpo_output <- dcpo$sample(
    data = dcpo_input[1:13], 
    max_treedepth = 14,
    adapt_delta = 0.99,
    step_size = 0.005,
    seed = 324, 
    chains = 4, 
    parallel_chains = 4,
    iter_warmup = iter/2,
    iter_sampling = iter/2,
    refresh = iter/50
)

results_path <- here::here(file.path("data", 
                                     iter, 
                                     {str_replace_all(Sys.time(),
                                                      "[- :]",
                                                      "") %>%
                                             str_replace("\\d{2}.\\d+$",
                                                         "")}))

dir.create(results_path, 
           showWarnings = FALSE, 
           recursive = TRUE)

dcpo_output$save_data_file(dir = results_path,
                           random = FALSE)
dcpo_output$save_output_files(dir = results_path,
                              random = FALSE)
```

```{r dcpo_output, eval=FALSE}
if (!exists("results_path")) {
    latest <- "202405120647"
    results_path <- here::here("data", "1000", latest)
    
    # Define OSF_PAT in .Renviron: https://docs.ropensci.org/osfr/articles/auth
    if (!file.exists(file.path(results_path, paste0("dcpo-", str_extract(latest, "\\d{12}"), "-1.csv")))) {
        dir.create(results_path,
                   showWarnings = FALSE,
                   recursive = TRUE)
        osf_retrieve_node("hdsfr") %>%
            osf_ls_files() %>%
            filter(str_detect(name, str_extract(latest, "\\d{12}"))) %>%
            osf_download(path = here::here("data", "1000"))
    }
    
    dcpo_output <- as_cmdstan_fit(here::here(results_path,
                                             list.files(results_path,
                                                        pattern = "csv$")))  
}

load(file = here::here("data", "dcpo_input.rda"))

theta_summary <- DCPOtools::summarize_dcpo_results(dcpo_input,
                                                   dcpo_output,
                                                   "theta")

save(theta_summary, file = here::here("data",
                                      "theta_summary.rda"))

theta_results <- extract_dcpo_results(dcpo_input,
                                      dcpo_output,
                                      par = "theta")

save(theta_results, file = here::here("data",
                                      "theta_results.rda"))

alpha_results <- summarize_dcpo_results(dcpo_input,
                                        dcpo_output = dcpo_output,
                                        pars = "alpha") %>% 
    transmute(item = question,
              dispersion = mean)

beta_results <- summarize_dcpo_results(dcpo_input,
                                       dcpo_output,
                                       "beta") %>% 
    group_by(question) %>% 
    summarize(difficulties0 = paste0(sprintf("%.2f", round(mean, 2)),
                                     collapse = ", ")) %>% 
    mutate(item = question,
           cp = if_else(str_detect(item, "threestate"),
                        2, 
                        as.numeric(str_extract(item, "\\d+")) - 1),
           term = str_glue("(( ?-?[0-9].[0-9][0-9]?,?){{{cp}}})"),
           difficulties = str_extract(difficulties0, 
                                      term) %>%
               str_replace(",$", "") %>% 
               str_trim()) %>% 
    transmute(item, difficulties)

save(alpha_results,
     beta_results,
     file = here::here("data",
                       "item_results.rda"))
```

```{r theta}
load(here::here("data",
                "theta_results.rda"))

load(here::here("data",
                "theta_summary.rda"))

res_cy <- nrow(theta_summary) %>% 
    scales::comma()

res_c <- theta_summary %>% 
    pull(country) %>% 
    unique() %>% 
    length()
```

```{r cs, fig.cap="PD Scores, Most Recent Available Year \\label{cs_mry}", fig.height=10, fig.width=8}
n_panes <- 2
axis_text_size <- 10

p1_data <- theta_summary %>%
    group_by(country) %>%
    top_n(1, year) %>%
    ungroup() %>%
    arrange(mean) %>%
    transmute(country_year = paste0(country, " (", year, ")") %>% 
                  str_replace("’", "'"),
              estimate = mean,
              conf.high = q90,
              conf.low = q10,
              pane = n_panes - (ntile(mean, n_panes) - 1),
              ranked = as.factor(ceiling(row_number())))

p_theta <- ggplot(p1_data,
                  aes(x = estimate, y = ranked)) +
    geom_segment(aes(x = conf.low, xend = conf.high,
                     y = ranked, yend = ranked),
                 na.rm = TRUE,
                 alpha = .4) +
    geom_point(fill = "black", shape = 21, size = .5, na.rm = TRUE) +
    theme_bw() + theme(legend.position="none",
                       axis.text.x  = element_text(size = axis_text_size,
                                                   angle = 90,
                                                   vjust = .45,
                                                   hjust = .95),
                       axis.text.y  = element_text(size = axis_text_size),
                       axis.title = element_blank(),
                       strip.background = element_blank(), 
                       strip.text = element_blank(),
                       panel.grid.major = element_line(size = .3),
                       panel.grid.minor = element_line(size = .15)) +
    scale_y_discrete(breaks = p1_data$ranked, labels=p1_data$country_year) +
    coord_cartesian(xlim=c(0, 1)) +
    facet_wrap(vars(pane), scales = "free", nrow = 1)


p_theta +
    plot_annotation(caption = "Note: Gray whiskers represent 80% credible intervals.")

bottom5 <- p1_data %>% 
    arrange(ranked) %>% 
    slice(1:5) %>% 
    pull(country_year) %>% 
    str_replace(" \\(.*", "") %>% 
    knitr::combine_words()

```

```{r ts, fig.cap="Political Discontent Scores Over Time Within OECD Democracies \\label{ts}", fig.height=9}

load(here::here("data", "theta_summary.rda"))

oecd_countries <- c("Australia", "Austria", "Belgium",
                    "Canada", "Chile", "Colombia",
                    "Costa Rica", "Czechia", "Denmark",
                    "Estonia", "Finland", "France", 
                    "Germany", "Greece", "Hungary",
                    "Iceland", "Ireland", "Israel",
                    "Italy", "Japan", "South Korea",
                    "Latvia", "Lithuania", "Luxembourg",
                    "Mexico", "Netherlands", "New Zealand",
                    "Norway", "Poland", "Portugal", 
                    "Slovakia", "Slovenia", "Spain",
                    "Sweden", "Switzerland", "Turkey", 
                    "United Kingdom", "United States")

c_res <- theta_summary %>% 
    filter(country %in% oecd_countries) %>%
    group_by(country) %>% 
    mutate(last_mean = last(mean)) %>% 
    ungroup() %>% 
    mutate(country = fct_reorder(country, last_mean, .desc = TRUE))

ggplot(data = c_res, aes(x = year, y = mean)) +
    theme_bw() +
    theme(legend.position = "none") +
    coord_cartesian(xlim = c(1968, 2024), ylim = c(0, 1)) +
    labs(x = NULL, y = "Political Discontent") +
    geom_ribbon(data = c_res, aes(ymin = q10, ymax = q90, linetype=NA), alpha = .25) +
    geom_line(data = c_res) +
    facet_wrap(~country, ncol = 5) +
    theme(axis.text.x  = element_text(size=7,
                                      angle = 90,
                                      vjust = .45,
                                      hjust = .95),
          strip.background = element_rect(fill = "white", colour = "white")) +
    plot_annotation(caption = "Note: Countries are ordered by their most recent political discontent score; gray shading represents 80% credible intervals.")
```

Consider validation tests with:
    democratic satisfaction
    trust in government
    Proud of: way democracy works (ISSP National Identity)
    incumbent vote share
    populist vote share

# Explaining Political Dissatisfaction

Data to test these hypotheses are drawn from several sources.
The Democratic Electoral Systems (DES) dataset updated in @Bormann2022 provides information about the timing of elections, yielding a dichotomous variable coded one in election years and zero when no election was held.
The three institutional variables are measured as in @Kittilson2010.
Data on parliamentarism, a dichotomous variable coded one in pure parliamentary systems and zero otherwise, is sourced from the DES.
Federalism is likewise dichotomous, coded one in countries with strong federal systems [see @Lijphart1999] and zero in all others.
Proportionality in the electoral system is measured using the Gallagher least-squares index of disproportionality, which measures the disparity between parties' vote shares and their seat shares [@Gallagher1991, 40-41; @Gallagher2023].
The context of good and bad economic conditions was measured with data on GDP per capita, national GDP growth, and unemployment from OECD.Stat [@OECD2023] and on the Gini index of disposable income inequality from the Standardized World Income Inequality Database [@Solt2020].

```{r des_download}
if (!file.exists(here("data-raw", "es_data-v41", "es_data-v4_1.csv"))) {
    dir.create(here("data-raw", "es_data-v41"))
    download.file("http://mattgolder.com/files/research/es_v4_codebook.pdf",
                  here("data-raw", "es_data-v41", "es_v4_codebook.pdf"))
    download.file("http://mattgolder.com/files/research/es_data-v41.zip",
                  here("data-raw", "es_data-v41", "es_data-v41.zip"))
    unzip(here("data-raw", "es_data-v41", "es_data-v41.zip"),
          exdir = here("data-raw", "es_data-v41"))
}
```

```{r des}
des_data <- vroom::vroom(here("data-raw",
                              "es_data-v41",
                              "es_data-v4_1.csv"),
                         guess_max = 5000,
                         show_col_types = FALSE) %>% 
    mutate(country = countrycode(country,
                                 origin = "country.name",
                                 destination = "country.name",
                                 custom_match = c("Serbia & Montenegro" =
                                                      "Serbia",
                                                  "The Co-operative Republic of Guyana" = "Guyana"))) %>% 
    filter(country %in% oecd_countries &
               country!="Turkey" &
               year > 1976) %>% 
    arrange(country, year) %>% 
    fill() %>% 
    group_by(country, year) %>% 
    summarize(regime = first(regime))
```

```{r disp}
if (!file.exists(here::here("data", "gallagher_data.rda"))) {
    if (!file.exists(here("data-raw", "ElectionIndices.pdf"))) {
        download.file("https://www.tcd.ie/Political_Science/about/people/michael_gallagher/ElSystems/Docts/ElectionIndices.pdf",
                      here("data-raw", "ElectionIndices.pdf"))
    }
    
    if (!file.exists(here("data-raw", "Disproportionality.csv"))) {
        download.file("https://raw.githubusercontent.com/christophergandrud/Disproportionality_Data/master/Disproportionality.csv", 
                      here("data-raw", "Disproportionality.csv"))
    }
    
    disp_add <- rio::import(here("data-raw", "Disproportionality.csv")) %>% 
        filter((country == "Korea, Republic of" & year < 2000) |
                   (country == "Colombia")) %>% 
        select(country, year, lsq = disproportionality) %>% 
        mutate(country = countrycode(country, "country.name", "country.name"))
    
    gallagher0 <- map(5:49, ~ extract_tables(here("data-raw",
                                                  "ElectionIndices.pdf"),
                                             pages = .x, output = "matrix") %>%
                          map(\(x) as_tibble(x, .name_repair = "unique")) %>%
                          list_rbind()) %>% 
        list_rbind()
    
    gallagher <- gallagher0 %>% 
        mutate(...1 = case_when(...1 == "Republic" ~ "Dominican Rep",
                                ...1 == "Ireland LSq" ~ "Northern Ireland",
                                ...1 == "Kingdom" ~ "United Kingdom",
                                ...1 == "(House)" ~ "United States",
                                ...1 == "Scotland" ~ "Scotland",
                                ...1 == "Barbuda" ~ "Antigua & Barbuda",
                                ...1 == "Hercegovina" ~ "Bosnia",
                                TRUE ~ ...1),
               country = countrycode(...1, "country.name", "country.name",
                                     warn = FALSE),
               country = case_when(...1 == "elections" ~ "Ireland EP",
                                   ...1 == "college)" ~ "U.S. Electoral College",
                                   ...1 == "Ireland LSq" ~ "Northern Ireland",
                                   ...1 == "Wales" ~ "Wales",
                                   ...1 == "Principe" ~ "Principe",
                                   TRUE ~ country),
               country2 = country) %>% 
        fill(country) %>% 
        filter(is.na(country2) & !...1 == "See Notes.") %>% 
        separate_wider_delim(...1, 
                             delim = " ", 
                             names = c("year", "info"),
                             too_few = "align_start",
                             too_many = "merge") %>% 
        mutate(lsq = str_replace_all(info, "[^\\d.]", ""),
               ...2 = if_else(...2 == "", lsq, ...2),
               month = str_extract(info, "[A-Z][a-z]{2}\\b") %>% 
                   base::match(month.abb)) %>% 
        filter((is.na(info) | !str_detect(info, "PR|list|SMD|SMP")) ) %>% 
        transmute(country = country,
                  year = as.numeric(year),
                  lsq = as.numeric(...2),
                  info = info,
                  month = month) %>% 
        filter(!is.na(lsq)) %>% 
        bind_rows(disp_add) %>% 
        group_by(country, year) %>% 
        arrange(country, -year, -month) %>% 
        distinct(country, year, .keep_all = TRUE) %>% 
        arrange(country, year) %>% 
        select(country, year, lsq)
    
    rio::export(gallagher, here::here("data", "gallagher_data.rda"))
} else {
    gallagher <- rio::import(here::here("data", "gallagher_data.rda"))
}    
```

```{r oecd}
if (!file.exists(here::here("data-raw", "oecd_data.rda"))) {
    
    oecd_growth_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/SNA_TABLE1/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.B1_GE.G/all?startTime=1980&endTime=2023"
    
    oecd_growth <- oecd_growth_link %>% 
        readSDMX() %>% 
        as_tibble() %>% 
        transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
                  year = as.numeric(obsTime),
                  growth = obsValue)
    
    oecd_unemployment_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/LFS_SEXAGE_I_R/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.MW.1564.UR.A/all?startTime=1980&endTime=2023"
    
    oecd_unemp <- oecd_unemployment_link %>% 
        readSDMX() %>% 
        as_tibble() %>% 
        transmute(country = countrycode(COUNTRY, "iso3c", "country.name"),
                  year = as.numeric(obsTime),
                  unemployment = obsValue)
    
    oecd_inflation_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/PRICES_CPI/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.CPALTT01.GY.A/all?startTime=1980&endTime=2023"
    
    oecd_inf <- oecd_inflation_link %>% 
        readSDMX() %>% 
        as_tibble() %>% 
        transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
                  year = as.numeric(obsTime),
                  inflation = obsValue)
    
    oecd_gdppc_link <- "https://stats.oecd.org/restsdmx/sdmx.ashx/GetData/SNA_TABLE1/AUS+AUT+BEL+CAN+CHL+COL+CRI+CZE+DNK+EST+FIN+FRA+DEU+GRC+HUN+ISL+IRL+ISR+ITA+JPN+KOR+LVA+LTU+LUX+MEX+NLD+NZL+NOR+POL+PRT+SVK+SVN+ESP+SWE+CHE+TUR+GBR+USA.B1_GE.HVPVOB/all?startTime=1980&endTime=2023"
    
    oecd_gdppc <- oecd_gdppc_link %>% 
        readSDMX() %>% 
        as_tibble() %>% 
        transmute(country = countrycode(LOCATION, "iso3c", "country.name"),
                  year = as.numeric(obsTime),
                  gdppc = obsValue)
    
    oecd <- oecd_gdppc %>% 
        left_join(oecd_growth, by = c("country", "year")) %>% 
        left_join(oecd_unemp, by = c("country", "year")) %>% 
        left_join(oecd_inf, by = c("country", "year")) %>% 
        group_by(country) %>% 
        mutate(across(gdppc:inflation,
                      ~ imputeTS::na_interpolation(.x)))
    
    rio::export(oecd, here::here("data-raw", "oecd_data.rda"))
} else {
    oecd <- rio::import(here::here("data-raw", "oecd_data.rda"))
}

```

```{r swiid_data}
if (!file.exists(here("data-raw",
                      "swiid9_6",
                      "swiid9_6_summary.csv"))) {
    download.file("https://dataverse.harvard.edu/api/access/datafile/7878619", "data-raw/swiid9_6.zip")
    unzip(here("data-raw", "swiid9_6.zip"), exdir = here("data-raw"))
    file.remove(here("data-raw", "swiid9_6.zip"))
}

swiid_summary <- read_csv(here("data-raw",
                               "swiid9_6",
                               "swiid9_6_summary.csv"),
                          col_types = "cddddddddd") %>% 
    mutate(country = countrycode::countrycode(country,
                                              "country.name",
                                              "country.name",
                                              warn = FALSE)) %>% 
    select(country, year, gini_disp, gini_disp_se)
```

```{r data_combo}
if (!file.exists(here::here("data", "data_combo.rda"))) {
    data_combo <- theta_summary %>% 
        filter(country %in% oecd_countries &
                   country!="Turkey") %>% 
        group_by(country) %>% 
        group_modify(~ add_row(.x, year = 0:4, .before = 0)) %>%
        mutate(year = case_when(year == 0 ~ lead(year, 5) - 5,
                                year == 1 ~ lead(year, 4) - 4,
                                year == 2 ~ lead(year, 3) - 3,
                                year == 3 ~ lead(year, 2) - 2,
                                year == 4 ~ lead(year, 1) - 1,
                                TRUE ~ year)) %>% 
        left_join(des_data, by = c("country", "year")) %>%
        left_join(gallagher,
                  by = c("country", "year")) %>% 
        mutate(parl = if_else(regime == 0, 1, 0),
               election = as.numeric(!is.na(regime) | !is.na(lsq))) %>% 
        select(-regime) %>% 
        fill(parl, .direction = "downup") %>% 
        left_join(oecd,
                  by = c("country", "year")) %>% 
        left_join(swiid_summary,
                  by = c("country", "year")) %>% 
        fill(lsq) %>% 
        drop_na(mean:gini_disp_se) %>% 
        mutate(federal = as.numeric(country %in% c("Australia", # decentralized = strong
                                                   "Belgium",
                                                   "Canada",
                                                   "Germany",
                                                   "Mexico",
                                                   "Switzerland",
                                                   "United States")),
               lsq_mean = mean(lsq),
               lsq_diff = lsq - lsq_mean,
               gini_mean = mean(gini_disp),
               gini_mean_se = sqrt(sum(gini_disp_se^2))/
                   length(gini_disp),
               gini_diff = (gini_disp - gini_mean),
               gini_diff_se = sqrt(gini_disp_se^2 + gini_mean_se^2)/2,
               gdppc_mean = mean(gdppc/1000),
               gdppc_diff = gdppc/1000 - gdppc_mean,
               growth_mean = mean(growth),
               growth_diff = growth - growth_mean,
               recession = if_else(growth >= 0, 0, 1),
               unemploy_mean = mean(unemployment),
               unemploy_diff = unemployment - unemploy_mean,
               inflation_mean = mean(inflation),
               inflation_diff = inflation - inflation_mean) %>% 
        ungroup()
    
    rio::export(data_combo, here::here("data", "data_combo.rda"))
} else {
    data_combo <- rio::import(here::here("data", "data_combo.rda"))
}
```

```{r analysis, include=FALSE}
if (!file.exists(here::here("data", "results.rda"))) {
    m1 <- brm(
        formula = bf(
            mean * 100 | mi(sd * 100) ~ election +
                parl +
                federal +
                lsq_mean + lsq_diff +
                gdppc_mean + gdppc_diff +
                growth_mean + growth_diff +
                unemploy_mean + unemploy_diff +
                me(gini_mean, gini_mean_se) +
                me(gini_diff, gini_diff_se) +
                (1 | country) + (1 | year)
        ),
        data = data_combo,
        backend = "cmdstanr",
        warmup = 1000,
        iter = 2000,
        chains = 4,
        cores = parallel::detectCores(),
        seed = 324
    )
    
    doubled_sd <- m1$data %>% 
        select(-`mean * 100`, -mean, -sd,
               -country, -year, -ends_with("_se")) %>% 
        summarize(across(everything(), by2sd)) %>% 
        pivot_longer(everything()) %>% 
        transmute(`.variable` = case_when(name == "gini_mean" ~ 
                                              "bsp_megini_meangini_mean_se",
                                          name == "gini_diff" ~
                                              "bsp_megini_diffgini_diff_se",
                                          TRUE ~ paste0("b_", name)),
                  var_names = c("Election Year",
                                "Parliamentarism",
                                "Federalism",
                                "Disproportionality, Mean",
                                "Disproportionality, Difference",
                                "GDPpc, Mean",
                                "GDPpc, Difference",
                                "GDP Growth, Mean",
                                "GDP Growth, Difference",
                                "Unemployment, Mean",
                                "Unemployment, Difference",
                                "Income Inequality, Mean",
                                "Income Inequality, Difference"),
                  sd2 = value)
    
    coef_data0 <- m1 %>% 
        tidybayes::gather_draws(`bs?p?_.*`, regex = TRUE) %>% 
        filter(!`.variable`=="b_Intercept") %>% 
        left_join(doubled_sd, by = join_by(.variable))
    
    cy_summary <- m1$data %>%
        count(country) %>%
        pull(n) %>%
        summary()
    
    save(m1, doubled_sd, coef_data0, cy_summary, file = here::here("data", "results.rda"))
} else {
    load(file = here::here("data", "results.rda"))
}

ess_perc <- {{dcpo_input_raw1 %>% 
        filter(country %in% oecd_countries & r==1) %>%
        count(item) %>%
        arrange(desc(n)) %>%
        slice(1) %>%
        pull(n)} * 100 / nrow(m1$data)} %>% 
    round()
```

The resulting dataset comprises the thirty-seven OECD democracies, each observed in twenty-one (Mexico) to forty (Ireland, Italy, the United Kingdom, and the United States) consecutive years (mean: `r cy_summary %>% nth(4) %>% round(1)` years, median: `r cy_summary %>% nth(3)` years).
Even among these relatively data-rich countries, our measure of macrointerest provides much more data than would otherwise be available: the richest single survey for these cases, the European Social Survey, covers only `r ess_perc`% of these country-years, does not provide annual data, and of course excludes entirely the nine OECD members in the Americas and around the Pacific Rim (see Appendix\nobreakspace{}\@ref(ESScomparison)).

@Shor2007 demonstrates that such pooled time series are best analyzed using a Bayesian multilevel model including varying intercepts for each country and each year. 
The former help account for heteroskedasticity across space due to, e.g., omitted variable bias, while permitting the inclusion of time-invariant predictors such as parliamentarism and federalism.
The latter take into account 'time shocks' that operate on all countries simultaneously [@Shor2007, 171-172].
Further, the 'within-between random effects' specification is employed, meaning each of the time-varying predictors is decomposed into its time-invariant country mean and the difference between each country-year value and this country mean; this specification is superior to fixed effects and other commonly used TSCS specifications for addressing omitted variable bias and endogeneity [@Bell2015].
The time-varying difference variables capture the short-term effects of the predictors, while the time-invariant country-mean variables reflect their---often different---long-run, "historical" effects [@Bell2015, 137].
Moreover, as we employ a Bayesian analysis, it is straightforward to incorporate the measurement uncertainty in the data for both macrointerest and income inequality directly into the model, with the estimated values of these variables treated as random draws from distributions with unknown true means but known standard deviations [@McElreath2016, 425-431; see also @Kurz2023, 15.1.2].
The model was estimated using the `brms` R package [@Burkner2017].

```{r resplot, fig.cap="Predicting Macrointerest in OECD Democracies \\label{model}", fig.height = 5, fig.width = 7.5}

ordered <- doubled_sd %>%
    pull(var_names) %>% 
    rev()

coef_data <- coef_data0 %>% 
    mutate(std_coef = round(.value * sd2, 1),
           term = factor(var_names, levels = ordered)) %>%
    ggdist::median_qi(std_coef, .width = c(.8, .9, .95)) %>%
    mutate(ci = paste0(round(.lower, 1), " to ", round(.upper, 1))) %>%
    left_join(doubled_sd, ., by = join_by(.variable))

coef_data0 %>% 
    mutate(std_coef = .value * sd2,
           term = factor(var_names, levels = ordered)) %>% 
    ggplot(aes(y = term, x = std_coef)) +
    stat_halfeye(.width = c(.8, .9, .95)) +
    geom_vline(xintercept = 0, linetype = "dashed") +
    coord_cartesian(xlim = c(-15, 15)) +
    theme_light() +
    xlab(NULL) +
    ylab(NULL) +
    plot_annotation(caption = "Notes: Dots indicate posterior means; whiskers, from thickest to thinnest, describe 80%,\n90%, and 95% credible intervals; shading depicts the posterior probability density function.")
```


Figure\nobreakspace{}\@ref(fig:resplot) displays the results.^[
Appendix\nobreakspace{}\@ref(resultstable) provides a tabular version.]
Consistent with the argument that campaigns bring attention-grabbing information to the public, macrointerest in election years is found to be `r get_coef("election", type = "std_coef")` points (95% credible interval: `r get_coef("election", type = "ci")` points) higher than in years without elections.
This accords with previous research finding small but well-estimated increases in political interest in election years [see, e.g., @Larsen2022].

The hypothesis that power-sharing institutions yield more public interest in politics is also supported.
Macrointerest is estimated to be `r get_coef("parl")` points higher in countries with parliamentary systems.
The point estimate for the difference in macrointerest between countries with and without federalism is estimated be `r get_coef("federal", type = "std_coef")` points, with `r round(p_direction(m1, parameters = "federal")[[2]]*100, 1)`% of the posterior distribution greater than zero.
And although disproportionality is not estimated to have long-run effects that consistently distinguish countries with more or less proportional electoral results, _changes_ in disproportionality appear to have an immediate negative effect: a two-standard-deviation increase in the Gallagher index yields `r get_coef("lsq_diff", type = "std_coef", abs = TRUE)` points less macrointerest (95% c.i.: `r get_coef("lsq_diff", type = "ci")`).

Regarding the debate on whether macrointerest is invigorated or instead discouraged by bad times, the evidence of our cross-national analysis of the impact of economic conditions falls on the side of the latter.
Supporting modernization theory, increases in per capita GDP have a positive short-term effect on aggregate political interest, with a two-standard-deviation increase associated with `r get_coef("gdppc_diff")` points more macrointerest.
The point estimate for the long-term, historical effect as evidenced by differences in mean levels across countries is found to be `r get_coef("gdppc_mean", type = "std_coef")` points, albeit with only `r round(p_direction(m1, parameters = "gdppc_mean")[[2]]*100, 1)`% of the posterior distribution greater than zero.
As predicted by relative power theory, the long-term effects of income inequality are strongly negative, with a two-standard-deviation difference across countries associated with `r get_coef("gini_mean", type = "std_coef", abs = TRUE)` points less macrointerest (95% c.i.: `r get_coef("gini_mean", type = "ci")` points).
Year-to-year changes in income inequality are found to make little difference---it would seem that, from one perspective, the influence of the wealthy over the political agenda does not change on such a short time scale, and from the other, that the public does not react to worsening conditions in the distribution of income with greater interest in its agents' actions.
The results with regard to growth in the national economy and with regard to unemployment similarly do not provide strong evidence of either negative or positive effects.
Still, taken as a whole, this evidence indicates that at least with regard to economic conditions, it is good times, not bad ones, that yield more macrointerest.



# Literature {.unlisted .unnumbered}

A test of citation [@Claassen2019;@HuEtAl2022a].

# Theory {.unlisted .unnumbered}

# Research Design and Results {.unlisted .unnumbered}

```{r data}
# load(here("data", "correct_cls_ajps.rda")) # https://osf.io/52u7n/download
# load(here("data", "expcor_cls_ajps.rda"))  # https://osf.io/cgxjd/download

```


See the descriptive statistics in @sec-app-descriptive.

See the full, numeric results in @sec-app-numeric.

# Summary and Discussion {.unlisted .unnumbered}

# Reference {.unlisted .unnumbered}

::: {#refs-main}
:::

\pagebreak

```{=tex}
\renewcommand{\baselinestretch}{1}
\selectfont
\maketitle
\selectfont

\pagenumbering{arabic}
\renewcommand*{\thepage}{A\arabic{page}}
\setcounter{page}{1}
\renewcommand*{\thefigure}{A\arabic{figure}}
\setcounter{figure}{0}
\renewcommand{\thetable}{A.\arabic{table}}
\setcounter{table}{0}
\renewcommand*{\thesection}{A\arabic{section}}
\setcounter{section}{0}

\vspace{-.5in}
\begin{center}
\begin{Large}
Online Supplementary Materials
\end{Large}
\end{center}

\tableofcontents
\newpage
```


\noindent Table A1: Indicators Used in the Support for Political Dissatisfaction Latent Variable Model
```{r dcpo_items}
load(here::here("data", "dcpo_input.rda"))
load(here::here("data", "item_results.rda"))

items_summary <- dcpo_input_raw1 %>%
dplyr::select(country, year, item, survey) %>%
separate_rows(survey, sep=",\\s+") %>% 
distinct() %>%
group_by(item) %>% 
mutate(survey = str_extract(survey, "^[a-z]*"),
all_surveys = paste0(unique(survey), collapse = ", ")) %>% 
ungroup() %>% 
distinct(country, year, item, .keep_all = TRUE) %>% 
group_by(item) %>% 
mutate(n_cy = n()) %>% 
ungroup() %>%
distinct(item, n_cy, all_surveys) %>% 
left_join(surveys_pd %>%
select(item, question_text, response_categories) %>%
distinct(item, .keep_all = TRUE),
by = "item") %>% 
left_join(alpha_results, by = "item") %>% 
left_join(beta_results, by = "item") %>% 
arrange(-n_cy)
```

```{r dcpo_items_table}
items_summary %>% 
transmute(`Survey\nItem\nCode` = item,
`Country-Years` = as.character(n_cy),
`Question Text` = str_replace(question_text, "([^(]*)\\(.*", "\\1"),
`Response Categories` = response_categories,
`Dispersion` = dispersion,
`Difficulties` = difficulties,
`Survey Dataset Codes*` = all_surveys) %>% 
modelsummary::datasummary_df(output = "kableExtra",
longtable = TRUE, 
title = "Survey Items Used to Estimate Public Political Discontent") %>% 
kableExtra::column_spec(1, width = "7em") %>%
kableExtra::column_spec(2, width = "4em") %>%
kableExtra::column_spec(3, width = "13em") %>%
kableExtra::column_spec(4, width = "16em") %>%
kableExtra::column_spec(5, width = "4em") %>%
kableExtra::column_spec(c(6, 7), width = "8em") %>% 
kableExtra::kable_styling(font_size = 7) %>%
kableExtra::kable_styling(latex_options = "repeat_header") %>%
kableExtra::kable_styling(latex_options = "striped") %>%
kableExtra::footnote(symbol = "Survey dataset codes correspond to those used in the DCPOtools R package (Solt, Hu, and Tai 2019).")
```

```{r obs, fig.cap = "Source Data Observations by Country and Year", fig.height = 9}
dcpo_input_plot <- dcpo_input_raw1 %>% 
mutate(country = str_replace(country, "’", "'")) %>% 
distinct(country, year, item, cc_rank) %>% 
group_by(country, year) %>% 
summarize(n = n(),
cc_rank = mean(cc_rank)) %>% 
ungroup() %>% 
distinct() |> 
mutate(continent = countrycode(country, "country.name", "continent",
warn = FALSE), 
continent = case_when(country %in% c("Kosovo", "Northern Ireland") ~
"Europe",
continent %in% c("Asia", "Oceania") ~
"Asia-Oceania",
TRUE ~ continent)) %>% 
group_by(continent) %>% 
mutate(mean_cc_rank = mean(cc_rank),
continent = as_factor(continent))

dcpo_input_plot %>%
filter(continent %in% c("Europe", "Asia-Oceania")) %>%
ggplot(aes(x = year, 
y = forcats::fct_reorder(country, cc_rank),
fill = n)) + 
geom_tile() +
scale_fill_steps(low = rev(hcl.colors(8, "inferno"))[1],
high = rev(hcl.colors(8, "inferno"))[8],
breaks =  seq(2, 16, 2),
show.limits = TRUE,
right = FALSE,
name = "Observations") +
labs(x = NULL, y = NULL) +
scale_x_continuous(breaks=seq(1968, 2024, 4),
sec.axis = dup_axis()) +
scale_y_discrete(position = "right") +
theme(axis.text.x  = element_text(size = 6),
axis.text.y  = element_text(size = 7),
strip.background = element_rect(fill = "white", colour = "white"),
strip.placement = "outside",
legend.position = c(0.13, 0.12),
legend.background = element_rect(fill = "white", colour = NA)) +
facet_wrap(~forcats::fct_reorder(continent, mean_cc_rank, .desc = TRUE),
ncol = 1,
scales = "free_y")
```

```{r obs2, fig.cap = "Source Data Observations by Country and Year, cont.", fig.height = 9}
dcpo_input_plot %>%
filter(!continent %in% c("Europe", "Asia-Oceania")) %>%
ggplot(aes(x = year, 
y = forcats::fct_reorder(country, cc_rank),
fill = n)) + 
geom_tile() +
scale_fill_steps(low = rev(hcl.colors(8, "inferno"))[1],
high = rev(hcl.colors(8, "inferno"))[8],
breaks =  seq(2, 16, 2),
show.limits = TRUE,
right = FALSE,
name = "Observations") +
labs(x = NULL, y = NULL) +
scale_x_continuous(breaks=seq(1968, 2024, 4),
sec.axis = dup_axis()) +
scale_y_discrete(position = "right") +
theme(axis.text.x  = element_text(size = 6),
axis.text.y  = element_text(size = 7),
strip.background = element_rect(fill = "white", colour = "white"),
strip.placement = "outside",
legend.position = c(0.13, 0.12),
legend.background = element_rect(fill = "white", colour = NA)) +
facet_wrap(~forcats::fct_reorder(continent, mean_cc_rank, .desc = TRUE),
ncol = 1,
scales = "free_y")
```


# Technical Details of DCPO {}

Another test of citation [@Rubin1987;@Claassen2020].

# Descriptive Statistics {#sec-app-descriptive}

Here's the appendix references list:

# Numeric Results {#sec-app-numeric}

# References {.unlisted .unnumbered}

::: {#refs-appendix}
:::